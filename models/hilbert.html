<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>HILANCO</title>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.1/css/bulma.min.css" integrity="sha512-ZRv40llEogRmoWgZwnsqke3HNzJ0kiI0+pcMgiz2bxO6Ew1DVBtWjVn0qjrXdT3+u+pSN36gLgmJiiQ3cQtyzA==" crossorigin="anonymous" />
        <script defer src="https://use.fontawesome.com/releases/v5.14.0/js/all.js"></script>
		<style>
			.section { padding-top: 20px !important; padding-bottom: 0px}
		</style>
    </head>
    <body>
        <section class="section">
            <div class="container">
			  <a href="https://hilanco.github.io/">
              <div class="columns">
                <div class="column is-8">				
                  <h1 class="title">
                    HILANCO
                  </h1>
                  <p class="subtitle">
                    Hungarian Intelligent Language Applications Consortium
                  </p>    
                </div>
                <div class="column is-4">
                  <figure class="image is-2-by-1">
                    <img src="../pictures/hilanco.png">
                  </figure>
                </div>
                </div>
				</a>
			</div>
		</section>
		<section class="section">
			<div class="container">
				<a class="button" href="https://hilanco.github.io">&laquo; Back to Home Page</a><br /><br />
                <div class="content">
					<h4 class="title is-4">
						HILBERT
					</h4>
                  <p class="has-text-justified">
					HILBERT is the <a href="https://rgai.inf.u-szeged.hu/sites/rgai.inf.u-szeged.hu/files/mszny2021.pdf" target="_blank">BERT-Large model</a> for Hungarian Trained on the 4 BN NYTI-BERT corpus. One of the pioneers of the revolutionary transformer models, BERT has caused a sweeping success in the field of neural NLP. It opened large opportunities in fields like text and speech processing, intelligent search, document classification and entity detection. HilBERT our Hungarian BERT-large model is likewise opens new perspectives in research and can be extremely helpful in creating novel chatbots, virtual assistants, and dialog agents with robust performance.
					<br />
					<br />
					<strong>To DOWNLOAD the models, please fill out the registration form: <a href="https://forms.gle/yuX3bGpArC1tYwTL6" target="_blank">&raquo; REGISTRATION FORM &laquo;</a></strong>
					<br />
					<br />
                    The development of the HILBERT modell was supported by Microsoft Hungary.
                  </p>
				</div>

            </div>
          </section>			
            <section class="section">

                <div class="container">
                    <h4 class="title is-4">
                        Publications
                    </h4>
                    <div class="content">
                        <ul>
                            <li><a href="https://towardsdatascience.com/train-bert-large-in-your-own-language-7685ee26b05b" target="_blank">Train BERT-Large in your own language</a></li>
                            <li><a href="https://rgai.inf.u-szeged.hu/sites/rgai.inf.u-szeged.hu/files/mszny2021.pdf" target="_blank">HILBERT, magyar nyelvű BERT-large modell tanítása felhő környezetben</a></li>
                        </ul>
                    </div>
                </div> 
				<br />
				<div class="container">
                    <h4 class="title is-4">
                        References
                    </h4>
                    <div class="content">
                        <ul>
                            <li><a href="https://arxiv.org/abs/1908.08962" target="_blank">Well-Read Students Learn Better: On the Importance of Pre-training Compact Models</a></li>
							<li><a href="https://github.com/microsoft/onnxruntime-training-examples/tree/master/nvidia-bert">Accelerate BERT pre-training with ONNX Runtime</a></li>
							<li><a href="https://github.com/google-research/bert" target="_blank">Github: BERT</a></li>
                        </ul>
                    </div>
                </div> 
            </section>	  
          <section class="section">
            <div class="container">
                <h4 class="title is-4">
                    More Language Models
                </h4>
                
				<div class="columns is-multiline">
                    <div class="column is-one-quarter">
                        <a href="https://hilanco.github.io/models/electra.html">
                        <div class="box">
                            <article class="media">
                              <div class="media-content">
                                <div class="content">
                                  <p>
                                    <strong>HIL-ELECTRA</strong>
									<br />
									&raquo; HIL-ELECTRA NYTI <br />- trained on NYTI-BERT corpus
									
									<br />
								    &raquo; HIL-ELECTRA wiki <br />- trained on Hungarian Wikipedia		
                                  </p>
                                </div>
                              </div>
                            </article>
                        </div>
                        </a>
                    </div>
                    <div class="column is-one-quarter">
                    <a href="https://hilanco.github.io/models/roberta.html">
                        <div class="box">
                            <article class="media">
                              <div class="media-content">
                                <div class="content">
                                  <p>
                                    <strong>HIL-RoBERTa</strong>
									<br />
									&raquo; HIL-RoBERTa wiki<br />- trained on Hungarian Wikipedia	
																
                                  </p>
                                </div>
                              </div>
                            </article>
                        </div>
                    </a>
                    </div>
                    <div class="column is-one-quarter">
                        <a href="https://hilanco.github.io/models/albert.html">
                        <div class="box">
                            <article class="media">
                              <div class="media-content">
                                <div class="content">
                                  <p>
                                    <strong>HIL-ALBERT</strong>
									<br />
									&raquo; HIL-ALBERT NYTI <br />- trained on 10% of NYTI-BERT corpus									
									<br />
								    &raquo; HIL-ALBERT wiki <br />- trained on Hungarian Wikipedia									
                                  </p>
                                </div>
                              </div>
                            </article>
                        </div>
                        </a>
                    </div>
					<div class="column is-one-quarter">
                    <a href="https://hilanco.github.io/models/sbert.html">
                        <div class="box">
                            <article class="media">
                              <div class="media-content">
                                <div class="content">
                                  <p>
                                    <strong>HIL-SBERT</strong>
                                    <br />
									Sentence-BERT models are fine-tuned BERT networks aimed at obtaining high-quality sentence embeddings.
                                  </p>
                                </div>
                              </div>
                            </article>
                        </div>
                    </a>
                    </div>
                </div>
			</section>
    </body>
</html>